{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bgPpghocFIa"
      },
      "source": [
        "# Emojify!\n",
        "\n",
        "Welcome to the second assignment! You're going to use word vector representations to build an Emojifier.\n",
        "ü§© üí´ üî•\n",
        "\n",
        "Have you ever wanted to make your text messages more expressive? Your emojifier app will help you do that.\n",
        "Rather than writing:\n",
        ">\"Congratulations on the promotion! Let's get coffee and talk. Love you!\"   \n",
        "\n",
        "The emojifier can automatically turn this into:\n",
        ">\"Congratulations on the promotion! üëç  Let's get coffee and talk. ‚òïÔ∏è Love you! ‚ù§Ô∏è\"\n",
        "\n",
        "You'll implement a model which inputs a sentence (such as \"Let's go see the baseball game tonight!\") and finds the most appropriate emoji to be used with this sentence (‚öæÔ∏è).\n",
        "\n",
        "### Using Word Vectors to Improve Emoji Lookups\n",
        "* In many emoji interfaces, you need to remember that ‚ù§Ô∏è  is the \"heart\" symbol rather than the \"love\" symbol.\n",
        "    * In other words, you'll have to remember to type \"heart\" to find the desired emoji, and typing \"love\" won't bring up that symbol.\n",
        "* You can make a more flexible emoji interface by using word vectors!\n",
        "* When using word vectors, you'll see that even if your training set explicitly relates only a few words to a particular emoji, your algorithm will be able to generalize and associate additional words in the test set to the same emoji.\n",
        "    * This works even if those additional words don't even appear in the training set.\n",
        "    * This allows you to build an accurate classifier mapping from sentences to emojis, even using a small training set.\n",
        "\n",
        "### What you'll build:\n",
        "1. In this exercise, you'll start with a baseline model (Emojifier-V1) using word embeddings.\n",
        "2. Then you will build a more sophisticated model (Emojifier-V2) that further incorporates an LSTM.\n",
        "\n",
        "By the end of this notebook, you'll be able to:\n",
        "\n",
        "* Create an embedding layer in Keras with pre-trained word vectors\n",
        "* Explain the advantages and disadvantages of the GloVe algorithm\n",
        "* Describe how negative sampling learns word vectors more efficiently than other methods\n",
        "* Build a sentiment classifier using word embeddings\n",
        "* Build and train a more sophisticated classifier using an LSTM\n",
        "\n",
        "üèÄ üëë\n",
        "\n",
        "üëÜ üòé\n",
        "\n",
        "(^^^ Emoji for \"skills\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKdcN0FDURpR"
      },
      "source": [
        "## **Download data and GloVE embeddings from Kaggle. For this purpose, you should download kaggle.json file from your Kaggle Account. (Create, if you still don't have one). Go to https://www.kaggle.com/settings/account and click Create New Token. Then, in the next cell upload the json file.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "GfOwRluczzV_",
        "outputId": "85fa6009-2cd1-4a9e-d67b-0597bd929b4b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-27285398-8514-420f-8b2d-1caf86de6696\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-27285398-8514-420f-8b2d-1caf86de6696\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"hibruuuh\",\"key\":\"12aa0bbb54766a666c678988401a1f99\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# You should upload the kaggle.json file once the popup appears\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9Wu7aa50PuU",
        "outputId": "f84aeb6f-795e-484c-9166-7b66b29f983f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 64 May 18 09:01 kaggle.json\n"
          ]
        }
      ],
      "source": [
        "# Verify that the kaggle.json is uploaded\n",
        "!ls -lha kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKPsxTxK0Ua4",
        "outputId": "32a21680-f57d-4bc0-a3a9-f8038c870ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/rtatman/glove-global-vectors-for-word-representation\n",
            "License(s): other\n",
            "Downloading glove-global-vectors-for-word-representation.zip to /content\n",
            " 93% 424M/458M [00:01<00:00, 336MB/s]\n",
            "100% 458M/458M [00:01<00:00, 406MB/s]\n",
            "Archive:  glove-global-vectors-for-word-representation.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n",
            "Dataset URL: https://www.kaggle.com/datasets/mruanova/emojify\n",
            "License(s): unknown\n",
            "Downloading emojify.zip to /content\n",
            "  0% 0.00/7.98k [00:00<?, ?B/s]\n",
            "100% 7.98k/7.98k [00:00<00:00, 13.1MB/s]\n",
            "Archive:  emojify.zip\n",
            "  inflating: emojify_data.csv        \n",
            "  inflating: tes.csv                 \n",
            "  inflating: tess.csv                \n",
            "  inflating: tesss.csv               \n",
            "  inflating: test_emoji.csv          \n",
            "  inflating: testing.csv             \n",
            "  inflating: train_emoji.csv         \n"
          ]
        }
      ],
      "source": [
        "#install kaggle package, move the kaggle.json in the appropriate folder and download the datasets.\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d rtatman/glove-global-vectors-for-word-representation\n",
        "!unzip glove-global-vectors-for-word-representation.zip\n",
        "!kaggle datasets download -d mruanova/emojify\n",
        "!unzip emojify.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsztVBA8cFIg"
      },
      "source": [
        "<a name='0'></a>\n",
        "## Packages\n",
        "\n",
        "Let's get started! Run the following cell to load the packages you're going to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrtvfbQHxuye",
        "outputId": "81e645dd-87fa-4530-c733-0388f6a834e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji==1.7.0\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m904.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171031 sha256=6715a51891d88cade7e9ba6565e974ad292fb91538feee07a3977bf6229fc0a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/22/e5/b69726d5e1a19795ecd3b3e7464b16c0f1d019aa94ff1c8578\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji==1.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lMZ9xg8MFHZU"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import emoji\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bFvBcjEyiZN"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QNVFGmIVygyX"
      },
      "outputs": [],
      "source": [
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r',  encoding=\"utf8\") as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            curr_word = line[0]\n",
        "            words.add(curr_word)\n",
        "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "\n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "            words_to_index[w] = i\n",
        "            index_to_words[i] = w\n",
        "            i = i + 1\n",
        "    return words_to_index, index_to_words, word_to_vec_map\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "\n",
        "def read_csv(filename = 'data/emojify_data.csv'):\n",
        "    phrase = []\n",
        "    emoji = []\n",
        "\n",
        "    with open (filename) as csvDataFile:\n",
        "        csvReader = csv.reader(csvDataFile)\n",
        "\n",
        "        for row in csvReader:\n",
        "            phrase.append(row[0])\n",
        "            emoji.append(row[1])\n",
        "\n",
        "    X = np.asarray(phrase)\n",
        "    Y = np.asarray(emoji, dtype=int)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)]\n",
        "    return Y\n",
        "\n",
        "\n",
        "emoji_dictionary = {#\"0\": \":red_heart:\",    # :heart: prints a black instead of red heart depending on the font\n",
        "                    \"0\": \"\\u2764\\ufe0f\",\n",
        "                    \"1\": \":baseball:\",\n",
        "                    \"2\": \":smile:\",\n",
        "                    \"3\": \":disappointed:\",\n",
        "                    \"4\": \":fork_and_knife:\"}\n",
        "\n",
        "def label_to_emoji(label):\n",
        "    \"\"\"\n",
        "    Converts a label (int or string) into the corresponding emoji code (string) ready to be printed\n",
        "    \"\"\"\n",
        "    return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)\n",
        "\n",
        "\n",
        "def print_predictions(X, pred):\n",
        "    print()\n",
        "    for i in range(X.shape[0]):\n",
        "        print(X[i], label_to_emoji(int(pred[i])))\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_actu, y_pred, title='Confusion matrix', cmap=plt.cm.gray_r):\n",
        "\n",
        "    df_confusion = pd.crosstab(y_actu, y_pred.reshape(y_pred.shape[0],), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
        "\n",
        "    df_conf_norm = df_confusion / df_confusion.sum(axis=1)\n",
        "\n",
        "    plt.matshow(df_confusion, cmap=cmap) # imshow\n",
        "    #plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(df_confusion.columns))\n",
        "    plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
        "    plt.yticks(tick_marks, df_confusion.index)\n",
        "    #plt.tight_layout()\n",
        "    plt.ylabel(df_confusion.index.name)\n",
        "    plt.xlabel(df_confusion.columns.name)\n",
        "\n",
        "\n",
        "\n",
        "def predict(X, Y, W, b, word_to_vec_map):\n",
        "    \"\"\"\n",
        "    Given X (sentences) and Y (emoji indices), predict emojis and compute the accuracy of your model over the given set.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data containing sentences, numpy array of shape (m, None)\n",
        "    Y -- labels, containing index of the label emoji, numpy array of shape (m, 1)\n",
        "\n",
        "    Returns:\n",
        "    pred -- numpy array of shape (m, 1) with your predictions\n",
        "    \"\"\"\n",
        "    m = X.shape[0]\n",
        "    pred = np.zeros((m, 1))\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "    # number of classes\n",
        "    n_h = word_to_vec_map[any_word].shape[0]\n",
        "\n",
        "    for j in range(m):                       # Loop over training examples\n",
        "\n",
        "        # Split jth test example (sentence) into list of lower case words\n",
        "        words = X[j].lower().split()\n",
        "\n",
        "        # Average words' vectors\n",
        "        avg = np.zeros((n_h,))\n",
        "        count = 0\n",
        "        for w in words:\n",
        "            if w in word_to_vec_map:\n",
        "                avg += word_to_vec_map[w]\n",
        "                count += 1\n",
        "\n",
        "        if count > 0:\n",
        "            avg = avg / count\n",
        "\n",
        "        # Forward propagation\n",
        "        Z = np.dot(W, avg) + b\n",
        "        A = softmax(Z)\n",
        "        pred[j] = np.argmax(A)\n",
        "\n",
        "    print(\"Accuracy: \"  + str(np.mean((pred[:] == Y.reshape(Y.shape[0],1)[:]))))\n",
        "\n",
        "    return pred\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av0PwZYscFIh"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1 - Baseline Model: Emojifier-V1\n",
        "\n",
        "<a name='1-1'></a>\n",
        "### 1.1 - Dataset EMOJISET\n",
        "\n",
        "Let's start by building a simple baseline classifier.\n",
        "\n",
        "You have a tiny dataset (X, Y) where:\n",
        "- X contains 127 sentences (strings).\n",
        "- Y contains an integer label between 0 and 4 corresponding to an emoji for each sentence.\n",
        "\n",
        "<img src=\"https://github.com/amanchadha/coursera-deep-learning-specialization/blob/master/C5%20-%20Sequence%20Models/Week%202/Emojify/images/data_set.png?raw=true\" style=\"width:700px;height:300px;\">\n",
        "<caption><center><font color='purple'><b>Figure 1</b>: EMOJISET - a classification problem with 5 classes. A few examples of sentences are given here. </center></caption>\n",
        "\n",
        "Load the dataset using the code below. The dataset is split between training (127 examples) and testing (56 examples)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OvuoZ8pWcFIi"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = read_csv('train_emoji.csv')\n",
        "X_test, Y_test = read_csv('tesss.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DjAuDbxrcFIi"
      },
      "outputs": [],
      "source": [
        "maxLen = len(max(X_train, key=len).split())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpbQIx7dcFIi"
      },
      "source": [
        "Run the following cell to print sentences from X_train and corresponding labels from Y_train.\n",
        "* Change `idx` to see different examples.\n",
        "* Note that due to the font used by iPython notebook, the heart emoji may be colored black rather than red."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE1Zd2SMcFIj",
        "outputId": "ec793700-aa6e-41f0-b825-383fbd19865f",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "never talk to me again üòû\n",
            "I am proud of your achievements üòÑ\n",
            "It is the worst day in my life üòû\n",
            "Miss you so much ‚ù§Ô∏è\n",
            "food is life üç¥\n",
            "I love you mum ‚ù§Ô∏è\n",
            "Stop saying bullshit üòû\n",
            "congratulations on your acceptance üòÑ\n",
            "The assignment is too long  üòû\n",
            "I want to go play ‚öæ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ac1e9ac051f0>:58: DeprecationWarning: The parameter 'use_aliases' in emoji.emojize() is deprecated and will be removed in version 2.0.0. Use language='alias' instead.\n",
            "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
            "  return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)\n"
          ]
        }
      ],
      "source": [
        "for idx in range(10):\n",
        "    print(X_train[idx], label_to_emoji(Y_train[idx]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS_N2pMpcFIk"
      },
      "source": [
        "<a name='1-2'></a>\n",
        "### 1.2 - Overview of the Emojifier-V1\n",
        "\n",
        "In this section, you'll implement a baseline model called \"Emojifier-v1\".  \n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/amanchadha/coursera-deep-learning-specialization/blob/master/C5%20-%20Sequence%20Models/Week%202/Emojify/images/image_1.png?raw=true\" style=\"width:900px;height:300px;\">\n",
        "    <caption><center><font color='purple'><b>Figure 2</b>: Baseline model (Emojifier-V1).</center></caption>\n",
        "</center></font>\n",
        "\n",
        "\n",
        "#### Inputs and Outputs\n",
        "* The input of the model is a string corresponding to a sentence (e.g. \"I love you\").\n",
        "* The output will be a probability vector of shape (1,5), (indicating that there are 5 emojis to choose from).\n",
        "* The (1,5) probability vector is passed to an argmax layer, which extracts the index of the emoji with the highest probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6nloeF5cFIl"
      },
      "source": [
        "#### One-hot Encoding\n",
        "* To get your labels into a format suitable for training a softmax classifier, convert $Y$ from its current shape  $(m, 1)$ into a \"one-hot representation\" $(m, 5)$,\n",
        "    * Each row is a one-hot vector giving the label of one example.\n",
        "    * Here, `Y_oh` stands for \"Y-one-hot\" in the variable names `Y_oh_train` and `Y_oh_test`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RhRTRwVncFIm"
      },
      "outputs": [],
      "source": [
        "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
        "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w3GRkw2cFIo"
      },
      "source": [
        "Now, see what `convert_to_one_hot()` did. Feel free to change `index` to print out different values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlHYeuBIcFIo",
        "outputId": "0c417c5e-d4f1-431b-9b51-78f17c06ce43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 'you are awful' has label index 3, which is emoji üòû\n",
            "Label index 3 in one-hot encoding format is [0. 0. 0. 1. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ac1e9ac051f0>:58: DeprecationWarning: The parameter 'use_aliases' in emoji.emojize() is deprecated and will be removed in version 2.0.0. Use language='alias' instead.\n",
            "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
            "  return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)\n"
          ]
        }
      ],
      "source": [
        "idx = 53\n",
        "print(f\"Sentence '{X_train[idx]}' has label index {Y_train[idx]}, which is emoji {label_to_emoji(Y_train[idx])}\", )\n",
        "print(f\"Label index {Y_train[idx]} in one-hot encoding format is {Y_oh_train[idx]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbFECkqAcFIp"
      },
      "source": [
        "All the data is now ready to be fed into the Emojify-V1 model. You're ready to implement the model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI8mJoafcFIp"
      },
      "source": [
        "<a name='1-3'></a>\n",
        "### 1.3 - Implementing Emojifier-V1\n",
        "\n",
        "As shown in Figure 2 (above), the first step is to:\n",
        "* Convert each word in the input sentence into their word vector representations.\n",
        "* Take an average of the word vectors.\n",
        "\n",
        "Similar to this week's previous assignment, you'll use pre-trained 50-dimensional GloVe embeddings.\n",
        "\n",
        "Run the following cell to load the `word_to_vec_map`, which contains all the vector representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QXI3avt7cFIq"
      },
      "outputs": [],
      "source": [
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JM-0zg6cFIr"
      },
      "source": [
        "You've loaded:\n",
        "- `word_to_index`: dictionary mapping from words to their indices in the vocabulary\n",
        "    - (400,001 words, with the valid indices ranging from 0 to 400,000)\n",
        "- `index_to_word`: dictionary mapping from indices to their corresponding words in the vocabulary\n",
        "- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation. (50-dimensional)\n",
        "\n",
        "Run the following cell to check if it works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB2ZN6ajcFIr",
        "outputId": "af136bb8-daff-41a3-bb98-74d59f903815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the index of cucumber in the vocabulary is 113317\n",
            "the 289846th word in the vocabulary is potatos\n"
          ]
        }
      ],
      "source": [
        "word = \"cucumber\"\n",
        "idx = 289846\n",
        "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
        "print(\"the\", str(idx) + \"th word in the vocabulary is\", index_to_word[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg9QpkR5cFIs"
      },
      "source": [
        "<a name='ex-1'></a>\n",
        "### Exercise 1 - sentence_to_avg\n",
        "\n",
        "Implement `sentence_to_avg()`\n",
        "\n",
        "You'll need to carry out two steps:\n",
        "\n",
        "1. Convert every sentence to lower-case, then split the sentence into a list of words.\n",
        "    * `X.lower()` and `X.split()` might be useful. üòâ\n",
        "2. For each word in the sentence, access its GloVe representation.\n",
        "    * Then take the average of all of these word vectors.\n",
        "    * You might use `numpy.zeros()`, which you can read more about [here]('https://numpy.org/doc/stable/reference/generated/numpy.zeros.html').\n",
        "    \n",
        "    \n",
        "#### Additional Hints\n",
        "* When creating the `avg` array of zeros, you'll want it to be a vector of the same shape as the other word vectors in the `word_to_vec_map`.  \n",
        "    * You can choose a word that exists in the `word_to_vec_map` and access its `.shape` field.\n",
        "    * Be careful not to hard-code the word that you access.  In other words, don't assume that if you see the word 'the' in the `word_to_vec_map` within this notebook, that this word will be in the `word_to_vec_map` when the function is being called by the automatic grader.\n",
        "\n",
        "**Hint**: you can use any one of the word vectors that you retrieved from the input `sentence` to find the shape of a word vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "buYjsIBecFIs"
      },
      "outputs": [],
      "source": [
        "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: sentence_to_avg\n",
        "\n",
        "def sentence_to_avg(sentence, word_to_vec_map):\n",
        "    \"\"\"\n",
        "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
        "    and averages its value into a single vector encoding the meaning of the sentence.\n",
        "\n",
        "    Arguments:\n",
        "    sentence -- string, one training example from X\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
        "\n",
        "    Returns:\n",
        "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
        "    \"\"\"\n",
        "    # Get a valid word contained in the word_to_vec_map.\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Step 1: Split sentence into list of lower case words (‚âà 1 line)\n",
        "    words = sentence.lower().split()\n",
        "\n",
        "    # Initialize the average word vector, should have the same shape as your word vectors.\n",
        "    avg = np.zeros(next(iter(word_to_vec_map.values())).shape)\n",
        "\n",
        "    # Initialize count to 0\n",
        "    count = 0\n",
        "\n",
        "    # Step 2: average the word vectors. You can loop over the words in the list \"words\".\n",
        "    for w in words:\n",
        "        if w in word_to_vec_map:\n",
        "            avg += word_to_vec_map[w] # element-wise addition\n",
        "            count += 1\n",
        "\n",
        "    if count > 0:\n",
        "        avg = avg / count # represents the mean of all word vectors in the sentence\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OwW-r6ecFIt",
        "outputId": "7d49e3cf-9e64-441b-e19c-bc49fac06073",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg = \n",
            " [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
            " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
            "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
            "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
            "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
            "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
            " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
            " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
            "  0.1445417   0.09808667]\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "# BEGIN UNIT TEST\n",
        "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", word_to_vec_map)\n",
        "print(\"avg = \\n\", avg)\n",
        "\n",
        "def sentence_to_avg_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    avg = target(\"a a_nw c_w a_s\", word_to_vec_map)\n",
        "    assert tuple(avg.shape) == tuple(word_to_vec_map['a'].shape),  \"Check the shape of your avg array\"\n",
        "    assert np.allclose(avg, [1.25, 2.5]),  \"Check that you are finding the 4 words\"\n",
        "    avg = target(\"love a a_nw c_w a_s\", word_to_vec_map)\n",
        "    assert np.allclose(avg, [1.25, 2.5]), \"Divide by count, not len(words)\"\n",
        "    avg = target(\"love\", word_to_vec_map)\n",
        "    assert np.allclose(avg, [0, 0]), \"Average of no words must give an array of zeros\"\n",
        "    avg = target(\"c_se foo a a_nw c_w a_s deeplearning c_nw\", word_to_vec_map)\n",
        "    assert np.allclose(avg, [0.1666667, 2.0]), \"Debug the last example\"\n",
        "\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "sentence_to_avg_test(sentence_to_avg)\n",
        "\n",
        "# END UNIT TEST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPPv5gmucFIv"
      },
      "source": [
        "<a name='1-4'></a>\n",
        "### 1.4 - Implement the Model\n",
        "\n",
        "You now have all the pieces to finish implementing the `model()` function!\n",
        "After using `sentence_to_avg()` you need to:\n",
        "* Pass the average through forward propagation\n",
        "* Compute the cost\n",
        "* Backpropagate to update the softmax parameters\n",
        "\n",
        "<a name='ex-2'></a>\n",
        "### Exercise 2 - model\n",
        "\n",
        "Implement the `model()` function described in Figure (2).\n",
        "\n",
        "* The equations you need to implement in the forward pass and to compute the cross-entropy cost are below:\n",
        "* The variable $Y_{oh}$ (\"Y one hot\") is the one-hot encoding of the output labels.\n",
        "\n",
        "$$ z^{(i)} = W . avg^{(i)} + b$$\n",
        "\n",
        "$$ a^{(i)} = softmax(z^{(i)})$$\n",
        "\n",
        "$$ \\mathcal{L}^{(i)} = - \\sum_{k = 0}^{n_y - 1} Y_{oh,k}^{(i)} * log(a^{(i)}_k)$$\n",
        "\n",
        "**Note**: It is possible to come up with a more efficient vectorized implementation. For now, just use nested for loops to better understand the algorithm, and for easier debugging.\n",
        "\n",
        "The function `softmax()` is provided, and has already been imported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "O_BzrO-TcFIv"
      },
      "outputs": [],
      "source": [
        "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: model\n",
        "\n",
        "def model(X, Y, word_to_vec_map, learning_rate = 0.015, num_iterations = 80):\n",
        "    \"\"\"\n",
        "    Model to train word vector representations in numpy.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data, numpy array of sentences as strings, of shape (m, 1)\n",
        "    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
        "    learning_rate -- learning_rate for the stochastic gradient descent algorithm\n",
        "    num_iterations -- number of iterations\n",
        "\n",
        "    Returns:\n",
        "    pred -- vector of predictions, numpy-array of shape (m, 1)\n",
        "    W -- weight matrix of the softmax layer, of shape (n_y, n_h)\n",
        "    b -- bias of the softmax layer, of shape (n_y,)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get a valid word contained in the word_to_vec_map\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "\n",
        "    # Initialize cost. It is needed during grading\n",
        "    cost = 0\n",
        "\n",
        "    # Define number of training examples\n",
        "    m = Y.shape[0]                             # number of training examples\n",
        "    n_y = len(np.unique(Y))                    # number of classes\n",
        "    n_h = word_to_vec_map[any_word].shape[0]   # dimensions of the GloVe vectors\n",
        "\n",
        "    # Initialize parameters using Xavier initialization\n",
        "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
        "    b = np.zeros((n_y,))\n",
        "\n",
        "    # Convert Y to Y_onehot with n_y classes\n",
        "    Y_oh = convert_to_one_hot(Y, C = n_y)\n",
        "\n",
        "    # Optimization loop\n",
        "    for t in range(num_iterations): # Loop over the number of iterations\n",
        "        for i in range(m):          # Loop over the training examples\n",
        "\n",
        "            ### START CODE HERE ### (‚âà 4 lines of code)\n",
        "            # Average the word vectors of the words from the i'th training example\n",
        "            avg = sentence_to_avg(X[i], word_to_vec_map)\n",
        "\n",
        "            # Forward propagate the avg through the softmax layer\n",
        "            z = np.dot(W, avg) + b\n",
        "            a = softmax(z)\n",
        "\n",
        "            # Compute cost using the i'th training label's one hot representation and \"A\" (the output of the softmax)\n",
        "            cost -= np.sum(Y_oh[i] * np.log(a))\n",
        "            ### END CODE HERE ###\n",
        "\n",
        "            # Compute gradients\n",
        "            dz = a - Y_oh[i]\n",
        "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
        "            db = dz\n",
        "\n",
        "            # Update parameters with Stochastic Gradient Descent\n",
        "            W = W - learning_rate * dW\n",
        "            b = b - learning_rate * db\n",
        "\n",
        "        if t % 10 == 0:\n",
        "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
        "            pred = predict(X, Y, W, b, word_to_vec_map) #predict is defined in emo_utils.py\n",
        "\n",
        "    return pred, W, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idsSj0OvxeSi",
        "outputId": "3da8f4bb-3451-4a04-97e1-1ce5294fda39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 --- cost = 2.6292406482200232\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 10 --- cost = 26.410584627690515\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 20 --- cost = 46.458605489807084\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 30 --- cost = 63.71392414489236\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 40 --- cost = 78.87140479430725\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 50 --- cost = 92.4457879779765\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 60 --- cost = 104.81783032802166\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 70 --- cost = 116.26811245674295\n",
            "Accuracy: 1.0\n",
            "Epoch: 80 --- cost = 127.00247604405966\n",
            "Accuracy: 1.0\n",
            "Epoch: 90 --- cost = 137.17137625202113\n",
            "Accuracy: 1.0\n",
            "Epoch: 100 --- cost = 146.8845932017863\n",
            "Accuracy: 1.0\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "# UNIT TEST\n",
        "def model_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2], 'a_n': [3, 4],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    # Training set. Sentences composed of a_* words will be of class 0 and sentences composed of c_* words will be of class 1\n",
        "    X = np.asarray(['a a_s synonym_of_a a_n c_sw', 'a a_s a_n c_sw', 'a_s  a a_n', 'synonym_of_a a a_s a_n c_sw', \" a_s a_n\",\n",
        "                    \" a a_s a_n c \", \" a_n  a c c c_e\",\n",
        "                   'c c_nw c_n c c_ne', 'c_e c c_se c_s', 'c_nw c a_s c_e c_e', 'c_e a_nw c_sw', 'c_sw c c_ne c_ne'])\n",
        "\n",
        "    Y = np.asarray([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "    np.random.seed(10)\n",
        "    pred, W, b = model(X, Y, word_to_vec_map, 0.0025, 110)\n",
        "\n",
        "    assert W.shape == (2, 2), \"W must be of shape 2 x 2\"\n",
        "    assert np.allclose(pred.transpose(), Y), \"Model must give a perfect accuracy\"\n",
        "    assert np.allclose(b[0], -1 * b[1]), \"b should be symmetric in this example\"\n",
        "\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "model_test(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7bWQtarcFIv",
        "outputId": "b6173489-d458-48e2-826c-1887f7789cfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(132,)\n",
            "(132,)\n",
            "(132, 5)\n",
            "never talk to me again\n",
            "3\n",
            "<class 'numpy.ndarray'>\n",
            "(20,)\n",
            "(20,)\n",
            "(132, 5)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
        "print(X_train[0])\n",
        "print(Y_train[0])\n",
        "print(type(X_train))\n",
        "Y = np.asarray([5, 0, 0, 5, 4, 4, 4, 6, 6, 4, 1, 1, 5, 6, 6, 3, 6, 3, 4, 4])\n",
        "print(Y.shape)\n",
        "\n",
        "X = np.asarray(['I am going to the bar tonight', 'I love you', 'miss you my dear',\n",
        " 'Lets go party and have drinks','Congrats on the new job','Congratulations',\n",
        " 'I am so happy for you', 'Why are you feeling bad', 'What is wrong with you',\n",
        " 'You totally deserve this prize', 'Let us go play football',\n",
        " 'Are you down for football this afternoon', 'Work hard play harder',\n",
        " 'It is surprising how people can be dumb sometimes',\n",
        " 'I am very disappointed','It is the best day in my life',\n",
        " 'I think I will end up alone','My life is so boring','Good job',\n",
        " 'Great so awesome'])\n",
        "\n",
        "print(X.shape)\n",
        "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
        "print(type(X_train))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdG05pgcFIw"
      },
      "source": [
        "Run the next cell to train your model and learn the softmax parameters (W, b). **The training process will take about 5 minutes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umWTqRcpcFIw",
        "outputId": "233a6f4c-dcbc-4858-ae54-d7389fb29d60",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 --- cost = 215.06303377494586\n",
            "Accuracy: 0.3939393939393939\n",
            "Epoch: 10 --- cost = 1624.2550805473768\n",
            "Accuracy: 0.7727272727272727\n",
            "Epoch: 20 --- cost = 2592.9680289088037\n",
            "Accuracy: 0.8106060606060606\n",
            "Epoch: 30 --- cost = 3392.832072176441\n",
            "Accuracy: 0.8484848484848485\n",
            "Epoch: 40 --- cost = 4091.668140770195\n",
            "Accuracy: 0.8712121212121212\n",
            "Epoch: 50 --- cost = 4720.325943016741\n",
            "Accuracy: 0.8863636363636364\n",
            "Epoch: 60 --- cost = 5296.412021428046\n",
            "Accuracy: 0.9090909090909091\n",
            "Epoch: 70 --- cost = 5831.246073256678\n",
            "Accuracy: 0.9318181818181818\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(1)\n",
        "pred, W, b = model(X_train, Y_train, word_to_vec_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygumNDIUcFIx"
      },
      "source": [
        "Great! Your model has pretty high accuracy on the training set. Now see how it does on the test set:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O862gcUicFIx"
      },
      "source": [
        "<a name='1-5'></a>\n",
        "### 1.5 - Examining Test Set Performance\n",
        "\n",
        "Note that the `predict` function used here is defined in `emo_util.spy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhb6CzhrcFIx",
        "outputId": "78e9c548-5812-4c95-aabf-c85ed21097ea",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "Accuracy: 0.9318181818181818\n",
            "Test set:\n",
            "Accuracy: 0.8571428571428571\n"
          ]
        }
      ],
      "source": [
        "print(\"Training set:\")\n",
        "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
        "print('Test set:')\n",
        "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wiSr9CXOxeSj"
      },
      "outputs": [],
      "source": [
        "def predict_single(sentence, W=W, b=b, word_to_vec_map=word_to_vec_map):\n",
        "    \"\"\"\n",
        "    Given X (sentences) and Y (emoji indices), predict emojis and compute the accuracy of your model over the given set.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data containing sentences, numpy array of shape (m, None)\n",
        "    Y -- labels, containing index of the label emoji, numpy array of shape (m, 1)\n",
        "\n",
        "    Returns:\n",
        "    pred -- numpy array of shape (m, 1) with your predictions\n",
        "    \"\"\"\n",
        "\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "    # number of classes\n",
        "    n_h = word_to_vec_map[any_word].shape[0]\n",
        "\n",
        "    # Split jth test example (sentence) into list of lower case words\n",
        "    words = sentence.lower().split()\n",
        "\n",
        "    # Average words' vectors\n",
        "    avg = np.zeros((n_h,))\n",
        "    count = 0\n",
        "    for w in words:\n",
        "        if w in word_to_vec_map:\n",
        "            avg += word_to_vec_map[w]\n",
        "            count += 1\n",
        "\n",
        "    if count > 0:\n",
        "        avg = avg / count\n",
        "\n",
        "    # Forward propagation\n",
        "    Z = np.dot(W, avg) + b\n",
        "    A = softmax(Z)\n",
        "    pred = np.argmax(A)\n",
        "\n",
        "\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "gQ4dimw2xeSl",
        "outputId": "369aca93-f22d-4039-c913-bcd907425211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ac1e9ac051f0>:58: DeprecationWarning: The parameter 'use_aliases' in emoji.emojize() is deprecated and will be removed in version 2.0.0. Use language='alias' instead.\n",
            "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
            "  return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‚ù§Ô∏è'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "label_to_emoji(int(predict_single(\"I love you.\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwmrm-aDcFIy"
      },
      "source": [
        "**Note**:\n",
        "* Random guessing would have had 20% accuracy, given that there are 5 classes. (1/5 = 20%).\n",
        "* This is pretty good performance after training on only 127 examples.\n",
        "\n",
        "\n",
        "#### The Model Matches Emojis to Relevant Words\n",
        "In the training set, the algorithm saw the sentence\n",
        ">\"I love you.\"\n",
        "\n",
        "with the label ‚ù§Ô∏è.\n",
        "* You can check that the word \"adore\" does not appear in the training set.\n",
        "* Nonetheless, let's see what happens if you write \"I adore you.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvCl7fUvcFIz",
        "outputId": "52b5e0cb-66e3-4e49-f135-090b38d4e42b",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8333333333333334\n",
            "\n",
            "i adore you ‚ù§Ô∏è\n",
            "i love you ‚ù§Ô∏è\n",
            "funny lol üòÑ\n",
            "lets play with a ball ‚öæ\n",
            "food is ready üç¥\n",
            "not feeling happy üòÑ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ac1e9ac051f0>:64: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print(X[i], label_to_emoji(int(pred[i])))\n",
            "<ipython-input-6-ac1e9ac051f0>:58: DeprecationWarning: The parameter 'use_aliases' in emoji.emojize() is deprecated and will be removed in version 2.0.0. Use language='alias' instead.\n",
            "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
            "  return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)\n"
          ]
        }
      ],
      "source": [
        "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
        "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
        "\n",
        "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
        "print_predictions(X_my_sentences, pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyC-BGqKcFI0"
      },
      "source": [
        "Amazing!\n",
        "* Because *adore* has a similar embedding as *love*, the algorithm has generalized correctly even to a word it has never seen before.\n",
        "* Words such as *heart*, *dear*, *beloved* or *adore* have embedding vectors similar to *love*.\n",
        "    * Feel free to modify the inputs above and try out a variety of input sentences.\n",
        "    * How well does it work?\n",
        "\n",
        "#### Word Ordering isn't Considered in this Model\n",
        "* Note that the model doesn't get the following sentence correct:\n",
        ">\"not feeling happy\"\n",
        "\n",
        "* This algorithm ignores word ordering, so is not good at understanding phrases like \"not happy.\"\n",
        "\n",
        "#### Confusion Matrix\n",
        "* Printing the confusion matrix can also help understand which classes are more difficult for your model.\n",
        "* A confusion matrix shows how often an example whose label is one class (\"actual\" class) is mislabeled by the algorithm with a different class (\"predicted\" class).\n",
        "\n",
        "Print the confusion matrix below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "Ab9aH9IQcFI1",
        "outputId": "fe8f4e70-a22c-439a-e40a-0b736d44c077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56,)\n",
            "           ‚ù§Ô∏è    ‚öæ    üòÑ    üòû   üç¥\n",
            "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
            "Actual                                 \n",
            "0            6    0    0    1    0    7\n",
            "1            0    8    0    0    0    8\n",
            "2            2    0   16    0    0   18\n",
            "3            1    1    2   12    0   16\n",
            "4            0    0    1    0    6    7\n",
            "All          9    9   19   13    6   56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ac1e9ac051f0>:58: DeprecationWarning: The parameter 'use_aliases' in emoji.emojize() is deprecated and will be removed in version 2.0.0. Use language='alias' instead.\n",
            "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
            "  return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# START SKIP FOR GRADING\n",
        "print(Y_test.shape)\n",
        "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
        "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
        "plot_confusion_matrix(Y_test, pred_test)\n",
        "# END SKIP FOR GRADING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm2o8SQIcFI1"
      },
      "source": [
        "<font color='blue'><b>What you should remember:</b>\n",
        "- Even with a mere 127 training examples, you can get a reasonably good model for Emojifying.\n",
        "    - This is due to the generalization power word vectors gives you.\n",
        "- Emojify-V1 will perform poorly on sentences such as *\"This movie is not good and not enjoyable\"*\n",
        "    - It doesn't understand combinations of words.\n",
        "    - It just averages all the words' embedding vectors together, without considering the ordering of words.\n",
        "</font>\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7sku0zrFwG8"
      },
      "source": [
        "## 2 - Emojifier-V2\n",
        "### Tasks\n",
        "\n",
        "1. Build an Emojifier using a RNN model\n",
        "2. What type of RNN did you use Smple RNN, GRU ... why did you choose the specific type\n",
        "3. Did you use a bidirectional and why\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8yVjqduOJTu"
      },
      "source": [
        "### Answers\n",
        "We use LSTM istead of vanilla RNN Model to:\n",
        "1. mitigate exploding/vanishing gradient problem\n",
        "2. keep track of the word ordering (relevant position between words)\n",
        "\n",
        "We use bidirectional lstm to keep track of the coontext both before and after a given word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vDkuc6wTxeSt"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Converts an array of sentences (strings) into an array of indices (integers).\n",
        "\n",
        "    Arguments:\n",
        "    X -- array of sentences (strings), shape (m, )\n",
        "    word_to_index -- dictionary mapping from words to their indices\n",
        "    max_len -- maximum length of a sentence\n",
        "\n",
        "    Returns:\n",
        "    X_indices -- array of indices corresponding to words in the sentences, shape (m, max_len)\n",
        "\"\"\"\n",
        "\n",
        "def sentences_to_indices(X, word_to_index, max_len):\n",
        "    m = len(X)\n",
        "    X_indices = np.zeros((m, max_len), dtype=int)\n",
        "\n",
        "    for i in range(m):\n",
        "        sentence_words = X[i].lower().split()\n",
        "        for j, word in enumerate(sentence_words[:max_len]):\n",
        "            if word in word_to_index:\n",
        "                X_indices[i, j] = word_to_index[word]\n",
        "\n",
        "    return torch.tensor(X_indices, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kxzvoK-gvHz6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# Prepare data\n",
        "maxLen = max([len(s.split()) for s in X_train])\n",
        "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
        "Y_train_tensor = torch.tensor(Y_train, dtype=torch.long)\n",
        "\n",
        "# DataLoader\n",
        "train_dataset = TensorDataset(X_train_indices, Y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Optimizer and loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "e1wW1BHrKIiK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Creates Embedding layer with pretrained GloVe vectors.\n",
        "    Converts words to dense vectors.\n",
        "\n",
        "    Arguments:\n",
        "    word_to_vec_map -- dictionary mapping words to GloVe vectors\n",
        "    word_to_index -- dictionary mapping words to indices\n",
        "\"\"\"\n",
        "\n",
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    vocab_len = len(word_to_index) + 1  # +1 for padding\n",
        "    emb_dim = next(iter(word_to_vec_map.values())).shape[0]\n",
        "\n",
        "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
        "    for word, idx in word_to_index.items():\n",
        "        emb_matrix[idx] = word_to_vec_map[word]\n",
        "\n",
        "    embedding_layer = nn.Embedding.from_pretrained(\n",
        "        torch.tensor(emb_matrix, dtype=torch.float), freeze=False\n",
        "    )\n",
        "\n",
        "    return embedding_layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gYAOKhiKKQ7Z"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Function to create the Emojifier-V2 model.\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the input, (max_len,)\n",
        "    word_to_vec_map -- dictionary mapping words to GloVe vectors\n",
        "    word_to_index -- dictionary mapping words to indices\n",
        "\"\"\"\n",
        "\n",
        "class EmojifyV2(nn.Module):\n",
        "    def __init__(self, word_to_vec_map, word_to_index):\n",
        "        super(EmojifyV2, self).__init__()\n",
        "        self.embedding = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding.embedding_dim, hidden_size=128, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(64 * 2, 5)  # Assuming 5 classes, 64 * 2 because we use bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "        x = self.dropout(hidden[-1])\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "AzEXZVyzuHdS"
      },
      "outputs": [],
      "source": [
        "def train_model(model, num_epochs, criterion, optimizer):\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "      epoch_loss = 0\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for x_batch, y_batch in train_loader:\n",
        "          x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(x_batch)\n",
        "          loss = criterion(outputs, y_batch)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          epoch_loss += loss.item()\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "          total += y_batch.size(0)\n",
        "          correct += (predicted == y_batch).sum().item()\n",
        "      if epoch % 10 == 0:\n",
        "          print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.4f} | Accuracy: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "od2HYZ6zuk54"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, Y_test, word_to_index, max_len, batch_size=32):\n",
        "    X_test_indices = sentences_to_indices(X_test, word_to_index, max_len)\n",
        "    Y_test_tensor = torch.tensor(Y_test, dtype=torch.long)\n",
        "\n",
        "    test_dataset = TensorDataset(X_test_indices, Y_test_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    true_positives = 0\n",
        "    predicted_positives = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in test_loader:\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(x_batch)\n",
        "            _, predicted = torch.max(outputs, 1) # argmax across class logits\n",
        "            total += y_batch.size(0)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "            true_positives += ((predicted == y_batch) & (predicted != 0)).sum().item()\n",
        "            predicted_positives += (predicted != 0).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    precision = 100 * true_positives / predicted_positives if predicted_positives > 0 else 0.0\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Precision (excluding class 0): {precision:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVbWAvR7uDYd",
        "outputId": "841c2472-eb23-4410-b78f-d88063cdea91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40 | Loss: 8.1014 | Accuracy: 17.42%\n",
            "Epoch 11/40 | Loss: 6.0614 | Accuracy: 70.45%\n",
            "Epoch 21/40 | Loss: 1.9456 | Accuracy: 89.39%\n",
            "Epoch 31/40 | Loss: 0.4776 | Accuracy: 99.24%\n"
          ]
        }
      ],
      "source": [
        "model = EmojifyV2(word_to_vec_map, word_to_index).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, 40, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V9P6WhkNNUp",
        "outputId": "a66d5570-d61b-4d3e-d199-d144ffed2c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.36%\n",
            "Precision (excluding class 0): 88.89%\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(model, X_test, Y_test, word_to_index, maxLen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FUriseOFwG8"
      },
      "source": [
        "## 3 - Emojifier-V3\n",
        "### Tasks\n",
        "\n",
        "1. Build an Emojifier using a Transformer based model\n",
        "2. What type of Transformer based did you use Full transformer, Decoder only ... why did you choose the specific type\n",
        "3. Can the problem be solved with an Full transformer only model and how?\n",
        "4. Can the problem be solved with an Decoder only model and how?\n",
        "5. Can the problem be solved with an Encoder only model and how?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_VM-pdYQ5PH"
      },
      "source": [
        "### Anwsers\n",
        "We use Encoder-only transformer\n",
        "Encoder-only models are designed for tasks like text classification. We want to classify the input sequence to a single class, not to generate output sequence.\n",
        "\n",
        "Using Full transofrmer will be overkill."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaKQHkdZ79c4"
      },
      "source": [
        "### Intuition\n",
        "\n",
        "We construct a simple feedforward network that encodes each input token (word) into an N-dimensional vector. Each token is initially represented as a one-hot vector and mapped to a continuous embedding that captures relationships between words. These embeddings are then fed into the transformer, which learns to capture the structure and meaning of entire sentences, including word order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GbjWohWkYDgB"
      },
      "outputs": [],
      "source": [
        "class EmojifyV3(nn.Module):\n",
        "    # running 2 parallel attention operations (heads) with different weights.\n",
        "    def __init__(self, word_to_vec_map, word_to_index, max_len, num_heads=2, ff_hidden=256, num_classes=5):\n",
        "        super(EmojifyV3, self).__init__()\n",
        "        self.embedding = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "        self.pos_embedding = nn.Embedding(max_len, self.embedding.embedding_dim)\n",
        "\n",
        "        # self attention\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=self.embedding.embedding_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=ff_hidden,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(self.embedding.embedding_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        positions = torch.arange(0, x.size(1)).unsqueeze(0).to(x.device)\n",
        "        x = self.embedding(x) + self.pos_embedding(positions)\n",
        "        encoded = self.transformer_encoder(x)\n",
        "        x = x = torch.mean(encoded, dim=1)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CocbQciNFvoC",
        "outputId": "ab90a907-1958-4cef-d4ad-6e46bcbc0715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40 | Loss: 8.0607 | Accuracy: 31.06%\n",
            "Epoch 11/40 | Loss: 6.4795 | Accuracy: 45.45%\n",
            "Epoch 21/40 | Loss: 3.7905 | Accuracy: 78.03%\n",
            "Epoch 31/40 | Loss: 0.8056 | Accuracy: 98.48%\n"
          ]
        }
      ],
      "source": [
        "model = EmojifyV3(\n",
        "    word_to_vec_map=word_to_vec_map,\n",
        "    word_to_index=word_to_index,\n",
        "    max_len=maxLen,\n",
        "    num_heads=2,\n",
        "    ff_hidden=256,\n",
        "    num_classes=5\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, 40, criterion, optimizer);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66ui1qwVqgJT",
        "outputId": "e29a10b9-3f4e-4601-91cd-743b6fdef09b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 78.57%\n",
            "Precision (excluding class 0): 76.92%\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(model, X_test,  Y_test, word_to_index, maxLen)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "coursera": {
      "schema_names": [
        "DLSC5W2-A2"
      ]
    },
    "kernelspec": {
      "display_name": "Python vevn",
      "language": "python",
      "name": ".venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}